{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark') \n",
    "import pandas as pd\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('cluster').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f16baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark-cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col,count,when,isnan\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import to_timestamp, date_format\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, minute, second\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.sql.functions import to_json, struct\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from cassandra.cluster import Cluster\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "import time\n",
    "from kafka import KafkaConsumer\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "from cassandra.cluster import Cluster\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('my_app').getOrCreate()\n",
    "df=spark.read.csv('uber-raw-data-aug14.csv',header=True,inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df = df.withColumn('date', split(df['Date/Time'], ' ')[0]).withColumn('time', split(df['Date/Time'], ' ')[1]).drop('Date/Time')\n",
    "df = df.select('date','Lat','Lon','Base')\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('date_new', to_timestamp('date', 'MM/dd/yyyy'))\n",
    "df = df.withColumn('year', year('date_new'))\n",
    "df = df.withColumn('month', month('date_new'))\n",
    "df = df.withColumn('day', dayofmonth('date_new'))\n",
    "df = df.drop('date_new')\n",
    "df = df.drop(\"date\")\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdc856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"my\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33d669",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"Base\", outputCol=\"Base_index\")\n",
    "indexed = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df22e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Lat', 'Lon','year','month','day', 'Base_index'], outputCol='features')\n",
    "data = assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=5, seed=100)\n",
    "model = kmeans.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ed914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"kmeans.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4190268",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'], \n",
    "                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n",
    "\n",
    "test_data_json = data.select(to_json(struct([data[x] for x in data.columns])).alias(\"value\")).collect()\n",
    "for data in test_data_json:\n",
    "    producer.send('test_topic', value=data['value'])\n",
    "    print(f\"{data['value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer('test_topic', bootstrap_servers=['localhost:9092'],\n",
    "                         auto_offset_reset='earliest', \n",
    "                         enable_auto_commit=True, \n",
    "                         value_deserializer=lambda m: json.loads(m.decode('utf-8')))\n",
    "for message in consumer:\n",
    "    data = message.value\n",
    "    json_object = json.loads(data)\n",
    "    df = spark.createDataFrame([(json_object['Lat'], json_object['Lon'],json_object['year'],json_object['month'],json_object['day'],json_object['Base_index'])], ['Lat', 'Lon','year','month','day','Base_index'])                                              \n",
    "    print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a71c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = KMeansModel.load(\"kmeans.model\")\n",
    "\n",
    "consumer = KafkaConsumer('test_topic', bootstrap_servers=['localhost:9092'],\n",
    "                         auto_offset_reset='earliest', \n",
    "                         enable_auto_commit=True, \n",
    "                         value_deserializer=lambda m: json.loads(m.decode('utf-8')))\n",
    "#output_file = \"file2.csv\"\n",
    "# with open(output_file, 'w') as file:\n",
    "#     file.write(\"features,predictions\\n\")  \n",
    "\n",
    "for message in consumer:\n",
    "    data = message.value\n",
    "    json_object = json.loads(data)\n",
    "    df = spark.createDataFrame([(json_object['Lat'], json_object['Lon'],json_object['year'],json_object['month'],json_object['day'],json_object['Base_index'])], ['Lat', 'Lon', 'year', 'month', 'day','Base_index'])\n",
    "    assembler = VectorAssembler(inputCols=['Lat', 'Lon', 'year', 'month', 'day','Base_index'], outputCol='features')\n",
    "    df_with_features = assembler.transform(df).select('features')\n",
    "    index = df_with_features\n",
    "\n",
    "    predictions = loaded_model.transform(index)\n",
    "    predictions_df = predictions.toPandas()\n",
    "#     predictions_df.to_csv(output_file, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = IndexToString(inputCol=\"Base_index\", outputCol=\"BaseString\")\n",
    "converted = converter.transform(predictions)\n",
    "output = converted.select(\"Lat\", \"Lon\",\"BaseString\" ,\"year\",\"month\",\"day\", \"prediction\")\n",
    "\n",
    "output.show()\n",
    "output_count = output.count()\n",
    "print(output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6696768",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.coalesce(1).write.csv(\"output.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe572a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb3749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
